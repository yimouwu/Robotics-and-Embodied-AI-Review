<h1 align="center">Robotics-and-Embodied-AI-Review</h1>

<p align="center">
  <strong>æœºå™¨äººå­¦ä¸å…·èº«æ™ºèƒ½å­¦ä¹ ç»¼è¿°åº“</strong><br>
  Robotics and Embodied AI Guide, Learning Resources, Course Materials, Daily Paper Reviews, Awesome Blogs...
</p>


> è¿™æ˜¯ä¸€ä¸ªä¸“æ³¨äºæœºå™¨äººå­¦ä¸å…·èº«æ™ºèƒ½é¢†åŸŸçš„ç»¼è¿°åº“ã€‚åŒ…æ‹¬é¢†åŸŸå…¥é—¨æŒ‡å—ã€é¢†åŸŸè®ºæ–‡ç»¼è¿°ã€æ•™æˆ/åšä¸»åˆ†äº«çš„ä¼˜è´¨èµ„æºç­‰ã€‚
å¸Œæœ›åˆå­¦è€…å¯ä»¥é€šè¿‡æœ¬ä»“åº“å¿«é€Ÿå»ºç«‹å…³äºç›¸å…³é¢†åŸŸçš„è®¤çŸ¥, ä¹Ÿå¸Œæœ›èƒ½ä¸ºå¤§ä½¬ä»¬æä¾›äº›æ–‡çŒ®é˜…è¯»ä¸Šçš„ä¾¿åˆ©ï½ æ¬¢è¿ç‚¹Starã€åˆ†äº«ä¸æPRğŸŒŸ~<br>ã€ <a href="https://github.com/yimouwu/Robotics-and-Embodied-AI-Review">Robotics-and-Embodied-AI-Review</a>, Latest Update: Jul. 1, 2025 ã€‘<img alt="GitHub repo stars" src="https://img.shields.io/github/stars/yimouwu/Robotics-and-Embodied-AI-Review"> ![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fyimouwu%2FRobotics-and-Embodied-AI-Review&label=Daily%20Visitors&labelColor=%234ccce4&countColor=%23d9e3f0) <img src="https://img.shields.io/badge/MIT-License-green.svg" alt="license">





# Contents - ç›®å½•
<nav>
<ul>
  <li><a href="#links">0. Useful Info - ä¼˜è´¨èµ„æºé“¾æ¥</a></li>
  
  <li><a href="#research-areas-guide">1. Research Areas Guide - ç ”ç©¶é¢†åŸŸå…¥é—¨æŒ‡å—</a>
    <ul>
      <li><a href="#Fundamentals-of-Robotics">1.1 Fundamentals of Robotics - æœºå™¨äººå­¦åŸºç¡€</a></li>
      <ul>
        <li><a href="#Markovian-Decision-Process">1.1.1 Introduction - åŸºæœ¬æ¦‚å¿µå…¥é—¨</a></li>
        <li><a href="#Mathematical-Concepts-and-Spatial-Transformation">1.1.2 Mathematical Concepts and Spatial Transformation - æ•°å­¦æ¦‚å¿µä¸ç©ºé—´è½¬æ¢</a></li>
        <li><a href="#Forward-Kinematics">1.1.3 Forward Kinematics - æ­£å‘è¿åŠ¨å­¦</a></li>
        <li><a href="#Inverse-Kinematics">1.1.4 Inverse Kinematics - é€†å‘è¿åŠ¨å­¦</a></li>
        <li><a href="#Velocity-Kinematics">1.1.5 Velocity Kinematics - é€Ÿåº¦è¿åŠ¨å­¦</a></li>
      </ul>
      <li><a href="#Control">1.2 Control - æ§åˆ¶</a></li>
      <ul>
        <li><a href="#Control-Concepts">1.2.1 Concepts - æ¦‚å¿µä¸æœ¯è¯­</a></li>
        <li><a href="#Control-System">1.2.2 Control System - æ§åˆ¶ç³»ç»Ÿ</a></li>
        <li><a href="#Controller">1.2.3 Controller - æ§åˆ¶å™¨</a></li>
        <ul>
          <li><a href="#PID">1.2.3.1 LQR Controller - LQR æ§åˆ¶å™¨</a></li>
          <li><a href="#PID">1.2.3.2 P.I.D. Controller - P.I.D. æ§åˆ¶å™¨</a></li>
        </ul>
      </ul>
      <li><a href="#Planning">1.3 Planning - è§„åˆ’</a></li>
      <ul>
        <li><a href="#Intro-to-Trajectory-and-Motion-Planning">1.3.1 Intro to Trajectory and Motion Planning - è½¨è¿¹ä¸è¿åŠ¨è§„åˆ’å…¥é—¨</a></li>
        <li><a href="#Search-Based-Methods">1.3.2 Search-Based Methods - åŸºäºæœç´¢çš„æ–¹æ³•</a></li>
        <li><a href="#Sampling-Based-Methods">1.3.3 Sampling-Based Methods - åŸºäºé‡‡æ ·çš„æ–¹æ³•</a></li>
        <li><a href="#Geometry-Based-Methods">1.3.4 Geometry-Based Methods - åŸºäºå‡ ä½•å­¦çš„æ–¹æ³•</a></li>
        <li><a href="#Optimization-Based-Methods">1.3.5 Optimization-Based Methods - åŸºäºæœ€ä¼˜åŒ–çš„æ–¹æ³•</a></li>
        <ul>
        <li><a href="#Model-Predictive-Control">1.3.5.1 Model Predictive Control - æ¨¡å‹é¢„æµ‹æ§åˆ¶</a></li>
        <ul>
          <li><a href="#Markovian-Decision-Process">1.3.5.1.1 Markovian Decision Process - é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹</a></li>
        </ul>
        </ul>
      </ul>
      <li><a href="#Perception">1.4 Perception - æ„ŸçŸ¥</a></li>
      <ul>
        <li><a href="#Kalman-Filter">1.4.1 Kalman Filter - å¡å°”æ›¼æ»¤æ³¢å™¨</a></li>
        <li><a href="#Scene-Understanding">1.4.2 Computer Vision - è®¡ç®—æœºè§†è§‰</a></li>
        <ul>
          <li><a href="#2D-Vision">1.4.2.1 2D Vision - äºŒç»´è§†è§‰</a></li>
          <li><a href="#3D-Vision">1.4.2.2 3D Vision - ä¸‰ç»´è§†è§‰</a></li>
          <li><a href="#3D-Vision">1.4.2.3 4D Vision - å››ç»´è§†è§‰</a></li>
          <li><a href="#Subdivision-of-application-domains">1.4.2.4 Subdivision of application domains - åº”ç”¨é¢†åŸŸç»†åˆ†</a></li>
          <ul>
            <li><a href="#Visual-Prompting">1.4.2.4.1 Visual Prompting - è§†è§‰æç¤º</a></li>
            <li><a href="#Affordance-Grounding">1.4.2.4.2 Affordance Grounding - å¯ä¾›æ€§é”šå®š</a></li>
            <ul>
              <li><a href="#Two-Dimension">1.4.2.4.2.1 2D - äºŒç»´</a></li>
              <li><a href="#Three-Dimension">1.4.2.4.2.2 3D - ä¸‰ç»´</a></li>
            </ul>
          </ul>
        </ul>
        <li><a href="#Scene-Understanding">1.4.2 Scene Understanding - åœºæ™¯ç†è§£</a></li>
        <ul>
        <li><a href="#Scene-Understanding">1.4.2.1 Segmentation - å›¾åƒåˆ†å‰²</a></li>
        </ul>
      </ul>
      <li><a href="#Learning">1.5 Learning - å­¦ä¹ </a></li>
      <ul>
        <li><a href="#Intro-to-Machine-Learning">1.5.1 Intro to Machine Learning - æœºå™¨å­¦ä¹ å…¥é—¨</a></li>
        <li><a href="#Reinforcement-Learning">1.5.2 Reinforcement Learning - å¼ºåŒ–å­¦ä¹ </a></li>
        <li><a href="#Imitation-Learning">1.5.3 Imitation Learning - æ¨¡ä»¿å­¦ä¹ </a></li>
      </ul>
      <li><a href="#Multi-Robot-Systems">1.6 Multi-Robot Systems - å¤šæœºå™¨äººç³»ç»Ÿ</a></li>
      <li><a href="#Simulation-and-Modeling">1.7 Simulation and Modeling - ä»¿çœŸä¸å»ºæ¨¡</a></li>
      <li><a href="#Physical-Interaction">1.8 Physical Interaction - ç‰©ç†äº¤äº’</a></li>
      <li><a href="#Ethics-and-Social-Implications">1.9 Ethics and Social Implications - ä¼¦ç†ä¸ç¤¾ä¼šé—®é¢˜</a></li>
    </ul>
  </li>
  
  <li><a href="#tools">2. Tools - å·¥å…·</a>
    <ul>
      <li><a href="#software">2.1 Software - è½¯ä»¶</a>
        <ul>
          <li><a href="#General-Tools">2.1.1 General Tools - å¸¸ç”¨å·¥å…·</a></li>
          <li><a href="#simulators">2.1.2 Simulators - ä»¿çœŸå™¨</a></li>
          <li><a href="#Robot-Description">2.1.3 Robot Description - æœºå™¨äººæè¿°æ ¼å¼</a></li>
        </ul>
      </li>
      <li><a href="#hardware">2.2 Hardware - ç¡¬ä»¶</a>
      </li>
    </ul>
  </li>
  
  <li><a href="#literature-review">3. Literature Review - æ–‡çŒ®ç»¼è¿°</a>
    <ul>
      <li><a href="#Traditional-Control">3.1 Traditional Control - ä¼ ç»Ÿæ§åˆ¶</a></li>
      <li><a href="#Model-Predictive-Control">3.2 Model Predictive Control - æ¨¡å‹é¢„æµ‹æ§åˆ¶</a></li>
      <li><a href="#Vision-Language-Model">3.3 Vision Language Model - è§†è§‰-è¯­è¨€æ¨¡å‹</a></li>
      <li><a href="#Vision-Language-Action">3.4 Vision Language Action Model - è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹</a></li>
      <li><a href="#Dual-System">3.5 Dual System - åŒç³»ç»Ÿ</a></li>
      <li><a href="#Model-Predictive-Control">3.3 Segmentation - å›¾åƒåˆ†å‰²</a></li>
    </ul>
  </li>
  
  <li><a href="#paper-list-link">4. Paper Lists - è®ºæ–‡åˆ—è¡¨</a></li>
  <li><a href="#acknowledgement">5. Acknowledgement - è‡´è°¢</a></li>
  <li><a href="#citation">ğŸ‘ Citation</a></li>
  <li><a href="#license">ğŸ·ï¸ License</a></li>
  <li><a href="#star-history">â­ï¸ Star History</a></li>
</ul>
</nav>



# 0. Useful Info - ä¼˜è´¨èµ„æºé“¾æ¥ <a id="links"></a>

###### - [å…·èº«çŸ¥è¯†åº“](https://yv6uc1awtjc.feishu.cn/wiki/WPTzw9ON0ivIVrkLjVocNZh8nLf?from=from_copylink) - å…·èº«æ™ºèƒ½çŸ¥è¯†åº“
###### - [Embodied-AI-Guide](https://github.com/tianxingchen/Embodied-AI-Guide) - å…·èº«æ™ºèƒ½ç³»ç»Ÿæ€§å­¦ä¹ æŒ‡å—
###### - [Awesome-Embodied-AI](https://github.com/yunlongdong/Awesome-Embodied-AI) - å…·èº«ç»å…¸å¼€æºé¡¹ç›®
###### - [å…·èº«æ™ºèƒ½æ‹›è´¤æ¦œ](https://github.com/StarCycle/Awesome-Embodied-AI-Job) - ä¸šç•Œå­¦ç•Œæ‹›è˜ä¿¡æ¯
<!-- ###### - [Writing AI Conference Papers: A Handbook for Beginners](https://github.com/hzwer/WritingAIPaper) - AIæ–¹å‘å¦‚ä½•å†™è®ºæ–‡
###### - [Hyperparameter-Optimization-of-Machine-Learning-Algorithms](https://github.com/LiYangHart/Hyperparameter-Optimization-of-Machine-Learning-Algorithms) - æœºå™¨å­¦ä¹ ç®—æ³•çš„è¶…å‚æ•°ä¼˜åŒ– -->




# 1. Research Areas Guide - ç ”ç©¶é¢†åŸŸå…¥é—¨æŒ‡å— <a id="research-areas-guide"></a>


## 1.1 Fundamentals of Robotics - æœºå™¨äººå­¦åŸºç¡€ <a id="Fundamentals-of-Robotics"></a>

### 1.1.1 Introduction - åŸºæœ¬æ¦‚å¿µå…¥é—¨ <a id="Markovian-Decision-Process"></a>

#### What Is A Robot? ä»€ä¹ˆæ˜¯æœºå™¨äººï¼Ÿ
- A well-accepted opinion: ä¸€ä¸ªå…¬è®¤çš„è§‚ç‚¹ï¼š
  â€“ Mechanical structure to interact with the environment ä¸ç¯å¢ƒäº’åŠ¨çš„æœºæ¢°ç»“æ„
  â€“ Electronics to sense, actuate and process information ä¼ æ„Ÿã€é©±åŠ¨å’Œå¤„ç†ä¿¡æ¯çš„ç”µå­å­¦
  â€“ Software to generate commands and autonomous motions to assist humans è½¯ä»¶ç”ŸæˆæŒ‡ä»¤å’Œè‡ªä¸»åŠ¨ä½œæ¥å¸®åŠ©äººç±»

#### Classification åˆ†ç±»
- Classification In terms of layout æŒ‰è®¾è®¡åˆ†ç±»
  - Manipulator: With extendable structures æœºæ¢°æ‰‹ï¼šå…·æœ‰å¯ä¼¸ç¼©ç»“æ„
  â€¢ robot arm æœºå™¨äººè‡‚/æœºæ¢°è‡‚
  â€¢ multi-fingered robot hands å¤šæŒ‡æœºå™¨äººæ‰‹

  - Mobile robot: With body mobility ç§»åŠ¨æœºå™¨äººï¼šå…·æœ‰èº«ä½“ç§»åŠ¨èƒ½åŠ›
  â€¢ wheeled mobile robots è½®å¼æœºå™¨äºº
  â€¢ humanoid robots ç±»äººæœºå™¨äºº
  â€¢ autonomous aerial robots è‡ªä¸»ç©ºä¸­æœºå™¨äºº
  â€¢ Unmanned Aerial Vehicle æ— äººæœº
  â€¢ â€¦

  - Manipulator + mobile platform: æœºæ¢°æ‰‹ç§»åŠ¨å¹³å°ï¼š
  â€¢ integration of above ä»¥ä¸Šçš„ç»“åˆ

- Classification In terms of functionality æŒ‰åŠŸèƒ½åˆ†ç±»
  â€¢ Industrial robots å·¥ä¸šæœºå™¨äºº
  â€¢ Logistic robots ç‰©æµæœºå™¨äºº
  â€¢ Service robots æœåŠ¡æœºå™¨äºº
  â€¢ Household robots å®¶åº­æœºå™¨äºº
  â€¢ Medical robots åŒ»ç–—æœºå™¨äºº
  â€¢ Professional service robots ä¸“ä¸šæœåŠ¡æœºå™¨äºº
  â€¢ Aerial/Underwater/Space robots ç©ºä¸­/æ°´ä¸‹/ç©ºé—´ æœºå™¨äºº
  â€¢ â€¦

#### Components of Robotic Systems æœºå™¨äººç³»ç»Ÿç»„æˆ
- Mechanical Structure: It is the body! Design, Kinematics and Dynamic models æœºæ¢°ç»“æ„ï¼šæ˜¯èº«ä½“ï¼è®¾è®¡ï¼Œè¿åŠ¨å­¦å’ŒåŠ¨åŠ›å­¦æ¨¡å‹
- Sensors: Measure robotsâ€™ own and environmental information. Position, Velocity, Force, Vision, etc ä¼ æ„Ÿå™¨ï¼šæµ‹é‡æœºå™¨äººè‡ªèº«å’Œç¯å¢ƒä¿¡æ¯ã€‚ä½ç½®ï¼Œé€Ÿåº¦ï¼ŒåŠ›ï¼Œè§†è§‰ç­‰
- Computing System: It is the brain! Tasks include Sensor Fusion and Integration, Motion planning, Control, etc. è®¡ç®—æœºç³»ç»Ÿï¼šæ˜¯å¤§è„‘ï¼ä»»åŠ¡åŒ…æ‹¬ä¼ æ„Ÿå™¨èåˆå’Œé›†æˆï¼Œè¿åŠ¨è§„åˆ’ï¼Œæ§åˆ¶ç­‰ã€‚
- Actuators: It generates power! There are electrical, hydraulic, and pneumatic actuators, etc é©±åŠ¨å™¨ï¼šå®ƒäº§ç”Ÿèƒ½é‡ï¼æœ‰ç”µåŠ¨ã€æ¶²å‹å’Œæ°”åŠ¨æ‰§è¡Œå™¨ç­‰
- Human-robot interfaces: Enable human-robot interactions. äººæœºç•Œé¢ï¼šå®ç°äººæœºäº¤äº’ã€‚

#### Robot Manipulator/Manipulation æœºæ¢°è‡‚
A Robot Manipulator is consisted of 1. Body(Mechanical body), 2. Actuators, 3. Sensors, 4. Controllers, 5. End-effectors æœºæ¢°è‡‚ç”±ä»¥ä¸‹éƒ¨åˆ†ç»„æˆ:1.æœ¬ä½“ï¼ˆæœºæ¢°æœ¬ä½“ï¼‰, 2.è‡´åŠ¨å™¨, 3.ä¼ æ„Ÿå™¨, 4. æ§åˆ¶å™¨, 5.æœ«ç«¯æ‰§è¡Œå™¨

- A manipulator consists of a number connected rigid bodies. æœºæ¢°è‡‚ç”±è‹¥å¹²ç›¸è¿çš„åˆšä½“ç»„æˆã€‚
  â€¢ The part connected to ground is called base ä¸åœ°é¢ç›¸è¿çš„éƒ¨åˆ†ç§°ä¸ºåº•åº§
  â€¢ The movable modules are called joints, the 1st joint, 2nd joint, â€¦ æ´»åŠ¨æ¨¡å—è¢«ç§°ä¸ºå…³èŠ‚ï¼Œç¬¬ä¸€å…³èŠ‚ï¼Œç¬¬äºŒå…³èŠ‚ï¼Œâ€¦
  â€¢ The rigid connections are called links(the 1st link, 2nd link...). åˆšæ€§è¿æ¥è¢«ç§°ä¸ºé“¾æ¥ï¼ˆç¬¬ä¸€é“¾æ¥ï¼Œç¬¬äºŒé“¾æ¥â€¦ï¼‰ã€‚

##### Joints å…³èŠ‚
- Joints are used to connect links, being key components to generate robot motions å…³èŠ‚ç”¨äºè¿æ¥è¿æ†ï¼Œæ˜¯äº§ç”Ÿæœºå™¨äººè¿åŠ¨çš„å…³é”®éƒ¨ä»¶
- Joints are classified into revolute joints and prismatic joints å…³èŠ‚åˆ†ä¸ºè½¬åŠ¨å…³èŠ‚å’Œç§»åŠ¨å…³èŠ‚
  â€¢ Prismatic joints: relative linear motion ç§»åŠ¨å…³èŠ‚ï¼šç›¸å¯¹çº¿æ€§è¿åŠ¨
  â€¢ Revolute joints: relative rotation è½¬åŠ¨å…³èŠ‚ï¼šç›¸å¯¹è½¬åŠ¨

##### End-effector æœ«ç«¯æ‰§è¡Œå™¨
- End-effector is the tool for a robot to carry out a task. æœ«ç«¯æ‰§è¡Œå™¨æ˜¯æœºå™¨äººæ‰§è¡Œä»»åŠ¡çš„å·¥å…·ã€‚
  - gripper é’³å­ï¼Œdrill é’»æœºï¼Œcutter åˆ‡å‰²æœºï¼Œwelding gun ç„Šæªï¼Œothers å…¶ä»–

##### Degree of Freedom (DOF) è‡ªç”±åº¦
- The degree of freedom (DOF) is a parameter describing degree of motion of a manipulator. è‡ªç”±åº¦ï¼ˆDOFï¼‰æ˜¯æè¿°æœºæ¢°è‡‚è¿åŠ¨ç¨‹åº¦çš„å‚æ•°ã€‚
  - It is equal to the number of joints (if there are only prismatic and revolute joints) of a robot manipulator. å®ƒç­‰äºæœºæ¢°è‡‚çš„å…³èŠ‚æ•°ï¼ˆå¦‚æœåªæœ‰ç§»åŠ¨å…³èŠ‚å’Œè½¬åŠ¨å…³èŠ‚ï¼‰ã€‚
  - It is equal to the number of parameters specifying the configuration of a manipulator or mechanical system. å®ƒç­‰äºæŒ‡å®šæœºæ¢°æ‰‹æˆ–æœºæ¢°ç³»ç»Ÿç»“æ„çš„å‚æ•°æ•°é‡ã€‚
- A mobile robot in a plane has 2 translational degrees and 1 rotational degree. åœ¨å¹³é¢ä¸Šç§»åŠ¨çš„æœºå™¨äººæœ‰2ä¸ªå¹³ç§»åº¦å’Œ1ä¸ªæ—‹è½¬åº¦ã€‚
- A free-flying rigid body in a space has 3 translational and 3 rotational degrees.

##### Actuation é©±åŠ¨å™¨


##### Sensors ä¼ æ„Ÿå™¨



### 1.1.2 Mathematical Concepts and Spatial Transformation - æ•°å­¦æ¦‚å¿µä¸ç©ºé—´è½¬æ¢ <a id="Mathematical-Concepts-and-Spatial-Transformation"></a>

##### Introduction
The configuration of a robot manipulator is determined by joint angles (variables) and joint-to-joint relationship (constant)
â€¢ Task specification is usually given in Cartesian space, i.e. the desired position and orientation of the end-effector are given in a Cartesian coordinates frame.
â€¢ Problem: How do we use joint information to obtain the position and orientation of the end-effector?

##### - Direction I: Forward Kinematics æ­£å‘è¿åŠ¨å­¦ï¼šæœºå™¨äººå­¦ä¸­çš„ä¸€ç§æ–¹æ³•ï¼Œç”¨äºè®¡ç®—æœºå™¨äººæœ«ç«¯æ‰§è¡Œå™¨åœ¨ç»™å®šå…³èŠ‚è§’åº¦ä¸‹çš„ä½ç½®å’Œæ–¹å‘ã€‚
â€¢ Definition: Given a set of joint variables , determine the position and orientation of the end-effector with respect to a task (world, inertia) coordinate frame. ç»™å®šä¸€ç»„å…³èŠ‚å˜é‡ï¼Œç¡®å®šæœ«ç«¯æ‰§è¡Œå™¨ç›¸å¯¹äºä»»åŠ¡ï¼ˆä¸–ç•Œï¼Œæƒ¯æ€§ï¼‰åæ ‡ç³»çš„ä½ç½®å’Œæ–¹å‘ã€‚
![alt text](image/image1.png)

##### - Direction II: Inverse Kinematics é€†å‘è¿åŠ¨å­¦ï¼šä¸€ç§æ•°å­¦è¿‡ç¨‹ï¼Œä»å…¶ä»–æ•°æ®æ¯”å¦‚ç¬›å¡å°”åæ ‡ç³»ä¸‹çš„ç©ºé—´ä½å§¿ä¸­æ¢å¤ç‰©ä½“çš„è¿åŠ¨å‚æ•°ï¼Œå¸¸ç”¨äºæœºå™¨äººæŠ€æœ¯ã€‚
â€¢ Definition: Given a position and orientation of the end-effector, find the corresponding joint variables of the robot manipulator. ç»™å®šæœ«ç«¯æ‰§è¡Œå™¨çš„ä½ç½®å’Œå§¿æ€ï¼Œæ±‚å‡ºæœºå™¨äººæœºæ¢°è‡‚ç›¸åº”çš„å…³èŠ‚å˜é‡ã€‚
![alt text](image/image2.png)

### 1.1.3 Forward Kinematics - æ­£å‘è¿åŠ¨å­¦ <a id="Forward-Kinematics"></a>
(Coming Soon...)  

### 1.1.4 Inverse Kinematics - é€†å‘è¿åŠ¨å­¦ <a id="Inverse-Kinematics"></a>
(Coming Soon...)  

### 1.1.5 Velocity Kinematics - é€Ÿåº¦è¿åŠ¨å­¦ <a id="Velocity-Kinematics"></a>
(Coming Soon...)  



## 1.2 Control - æ§åˆ¶ <a id="Control"></a>

### 1.2.1 Concepts - æ¦‚å¿µä¸æœ¯è¯­ <a id="Control-Concepts"></a>
(Coming Soon...)  

### 1.2.2 Control System - æ§åˆ¶ç³»ç»Ÿ <a id="Control-System"></a>
(Coming Soon...)  

### 1.2.3 Controller - æ§åˆ¶å™¨ <a id="Controller"></a>

#### 1.2.3.1 LQR Controller - LQR æ§åˆ¶å™¨ <a id="LQR"></a>
(Coming Soon...)  

#### 1.2.3.2 P.I.D. Controller - P.I.D. æ§åˆ¶å™¨ <a id="PID"></a>
(Coming Soon...)  



## 1.3 Planning - è§„åˆ’ <a id="Planning"></a>

### 1.3.1 Intro to Trajectory and Motion Planning - è½¨è¿¹ä¸è¿åŠ¨è§„åˆ’å…¥é—¨ <a id="Intro-to-Trajectory-and-Motion-Planning"></a>
'The problem of calculating and generating the robotâ€™s future motion sequence is called â€œplanningâ€' è®¡ç®—å’Œç”Ÿæˆæœºå™¨äººæœªæ¥è¿åŠ¨åºåˆ—çš„é—®é¢˜è¢«ç§°ä¸ºâ€œè§„åˆ’â€ã€‚
- Trajectory and motion planning are essential components in the field of robotics and autonomous systems. They involve determining the sequence of movements a robot must execute to perform a task effectively and safely within its environment. è½¨è¿¹å’Œè¿åŠ¨è§„åˆ’æ˜¯æœºå™¨äººå’Œè‡ªä¸»ç³»ç»Ÿé¢†åŸŸçš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚å®ƒä»¬åŒ…æ‹¬ç¡®å®šæœºå™¨äººå¿…é¡»æ‰§è¡Œçš„åŠ¨ä½œé¡ºåºï¼Œä»¥ä¾¿åœ¨å…¶ç¯å¢ƒä¸­æœ‰æ•ˆå®‰å…¨åœ°æ‰§è¡Œä»»åŠ¡ã€‚
![alt text](image/image3.png)

- End-effector motion planning: To generate in- between configurations given its initial and final configurations (or poses) æœ«ç«¯æ‰§è¡Œå™¨è¿åŠ¨è§„åˆ’ï¼šç»™å®šå…¶åˆå§‹å’Œæœ€ç»ˆæ„å‹ï¼ˆæˆ–å§¿æ€ï¼‰ç”Ÿæˆä¸­é—´æ„å‹

- Planning results could directly affect the robotâ€™s automation performance è§„åˆ’ç»“æœä¼šç›´æ¥å½±å“æœºå™¨äººçš„è‡ªåŠ¨åŒ–æ€§èƒ½

- Constraints include safety(Obstacle avoidance, singularity avoidance), efficiency(Fast tasks in industry), economy(To generate lowest cost), etc. çº¦æŸåŒ…æ‹¬å®‰å…¨æ€§ï¼ˆé¿éšœï¼Œå¥‡å¼‚ç‚¹è§„é¿ï¼‰ï¼Œæ•ˆç‡ï¼ˆå·¥ä¸šä¸­çš„å¿«é€Ÿä»»åŠ¡ï¼‰ï¼Œç»æµæ€§ï¼ˆäº§ç”Ÿæœ€ä½æˆæœ¬ï¼‰ç­‰ã€‚

##### There are different types of planning problems: ä¸åŒç±»å‹çš„è§„åˆ’é—®é¢˜
â€¢ Motion Planning è¿åŠ¨è§„åˆ’; â€¢ Path Planning è·¯å¾„è§„åˆ’; â€¢ Trajectory Planning è½¨è¿¹è§„åˆ’
![alt text](image/image4.png)
- Relationship
![alt text](image/image5.png)

##### Components in planning è§„åˆ’çš„ç»„æˆéƒ¨åˆ†
â€¢ Boundary constraints è¾¹ç•Œé™åˆ¶/çº¦æŸ; â€¢ Motion geometric profiles è¿åŠ¨å‡ ä½•è½®å»“; â€¢ Other constraints å…¶ä»–çº¦æŸ

##### Trajectory generation è½¨è¿¹ç”Ÿæˆ






### 1.3.2 Search-Based Methods - åŸºäºæœç´¢çš„æ–¹æ³• <a id="Search-Based-Methods"></a>
- Dijkstraâ€™s method
  - From the starting point, search every adjacent point in each new step until reaching the goal, then find the shortest path among all the goal-reachable solutions




### 1.3.3 Sampling-Based Methods - åŸºäºé‡‡æ ·çš„æ–¹æ³• <a id="Sampling-Based-Methods"></a>
(Coming Soon...)  



### 1.3.4 Geometry-Based Methods - åŸºäºå‡ ä½•å­¦çš„æ–¹æ³• <a id="Geometry-Based-Methods"></a>
(Coming Soon...)  



### 1.3.5 Optimization-Based Methods - åŸºäºæœ€ä¼˜åŒ–çš„æ–¹æ³• <a id="Optimization-Based-Methods"></a>
(Coming Soon...)  

#### 1.3.5.1 Model Predictive Control - æ¨¡å‹é¢„æµ‹æ§åˆ¶ <a id="Model-Predictive-Control"></a>
(Coming Soon...)  

##### 1.3.5.1.1 Markovian Decision Process - é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ <a id="Markovian-Decision-Process"></a>
(Coming Soon...)  




## 1.4 Perception - æ„ŸçŸ¥ <a id="Perception"></a>

### 1.4.1 Kalman Filter - å¡å°”æ›¼æ»¤æ³¢å™¨ <a id="Kalman-Filter"></a>

### Introduction

The **Kalman Filter** is a mathematical algorithm that provides an efficient computational solution to estimate the state of a dynamic system from a series of incomplete and noisy measurements. It is widely used in control systems, navigation, signal processing, and econometrics due to its ability to extract useful information from noisy data. å¡å°”æ›¼æ»¤æ³¢æ˜¯ä¸€ç§æ•°å­¦ç®—æ³•ï¼Œå®ƒæä¾›äº†ä¸€ç§æœ‰æ•ˆçš„è®¡ç®—è§£å†³æ–¹æ¡ˆï¼Œä»ä¸€ç³»åˆ—ä¸å®Œæ•´å’Œæœ‰å™ªå£°çš„æµ‹é‡ä¸­ä¼°è®¡åŠ¨æ€ç³»ç»Ÿçš„çŠ¶æ€ã€‚ç”±äºå®ƒèƒ½å¤Ÿä»å™ªå£°æ•°æ®ä¸­æå–æœ‰ç”¨çš„ä¿¡æ¯ï¼Œå› æ­¤è¢«å¹¿æ³›åº”ç”¨äºæ§åˆ¶ç³»ç»Ÿã€å¯¼èˆªã€ä¿¡å·å¤„ç†å’Œè®¡é‡ç»æµå­¦ä¸­ã€‚


### 1.4.1.1. What is the Kalman Filter?

#### 1.4.1.1.1. Overview

The Kalman Filter is a recursive estimator that estimates the state of a discrete-time controlled process governed by a linear stochastic difference equation. It operates in a two-step process: å¡å°”æ›¼æ»¤æ³¢å™¨æ˜¯ä¸€ç§é€’å½’ä¼°è®¡å™¨ï¼Œç”¨äºä¼°è®¡ç”±çº¿æ€§éšæœºå·®åˆ†æ–¹ç¨‹æ§åˆ¶çš„ç¦»æ•£æ—¶é—´æ§åˆ¶è¿‡ç¨‹çš„çŠ¶æ€ã€‚å®ƒåˆ†ä¸ºä¸¤æ­¥ï¼š

1. **Prediction Step:** The filter produces estimates of the current state variables, along with their uncertainties.   **é¢„æµ‹æ­¥éª¤ï¼š** è¿‡æ»¤å™¨äº§ç”Ÿå½“å‰çŠ¶æ€å˜é‡çš„ä¼°è®¡ï¼Œä»¥åŠå®ƒä»¬çš„ä¸ç¡®å®šæ€§ã€‚
2. **Update Step (Correction):** Once a new measurement is observed, these predictions are updated using a weighted average, with more weight given to estimates with higher certainty.   **æ›´æ–°æ­¥éª¤ï¼ˆä¿®æ­£ï¼‰ï¼š** ä¸€æ—¦è§‚å¯Ÿåˆ°æ–°çš„æµ‹é‡ç»“æœï¼Œè¿™äº›é¢„æµ‹å°†ä½¿ç”¨åŠ æƒå¹³å‡å€¼è¿›è¡Œæ›´æ–°ï¼Œå¹¶å°†æ›´å¤šçš„æƒé‡èµ‹äºˆå…·æœ‰æ›´é«˜ç¡®å®šæ€§çš„ä¼°è®¡ã€‚

#### 1.4.1.1.2. Mathematical Foundations

The Kalman Filter assumes the following: å¡å°”æ›¼æ»¤æ³¢å™¨å‡è®¾å¦‚ä¸‹

- The system is **linear**. è¯¥ç³»ç»Ÿæ˜¯çº¿æ€§çš„ã€‚
- The system dynamics and measurement equations are known. ç³»ç»ŸåŠ¨åŠ›å­¦å’Œæµ‹é‡æ–¹ç¨‹æ˜¯å·²çŸ¥çš„ã€‚
- The process noise and measurement noise are both **Gaussian**, with zero mean and known covariance. è¿‡ç¨‹å™ªå£°å’Œæµ‹é‡å™ªå£°å‡ä¸º**é«˜æ–¯å™ªå£°**ï¼Œå‡å€¼ä¸ºé›¶ï¼Œåæ–¹å·®å·²çŸ¥ã€‚

**State-Space Representation çŠ¶æ€ç©ºé—´è¡¨ç¤º:** 

The system can be represented in state-space form:

1. **State Equation (Process Model):**
   \[
   \mathbf{x}_{k} = \mathbf{A}_{k}\mathbf{x}_{k-1} + \mathbf{B}_{k}\mathbf{u}_{k} + \mathbf{w}_{k}
   \]

2. **Measurement Equation:**
   \[
   \mathbf{z}_{k} = \mathbf{H}_{k}\mathbf{x}_{k} + \mathbf{v}_{k}
   \]

**Where:**

- \(\mathbf{x}_{k}\): State vector at time \(k\).
- \(\mathbf{A}_{k}\): State transition matrix.
- \(\mathbf{B}_{k}\): Control input matrix.
- \(\mathbf{u}_{k}\): Control input vector.
- \(\mathbf{w}_{k}\): Process noise (assumed to be Gaussian with covariance \(\mathbf{Q}_{k}\)).
- \(\mathbf{z}_{k}\): Measurement vector at time \(k\).
- \(\mathbf{H}_{k}\): Measurement matrix.
- \(\mathbf{v}_{k}\): Measurement noise (assumed to be Gaussian with covariance \(\mathbf{R}_{k}\)).


### 1.4.1.2. Variants of the Kalman Filter

Due to limitations in the basic Kalman Filter (e.g., linearity assumptions), several variants have been developed to handle nonlinear systems, improve numerical stability, and address specific application requirements.

#### 1.4.1.2.1. Extended Kalman Filter (EKF)

##### 1.4.1.2.1.1. Overview

The EKF linearizes the nonlinear system around the current estimate using Taylor series expansion. It approximates the system dynamics and measurement equations to first-order terms.

##### 1.4.1.2.1.2. Mathematical Formulation

For a system described by nonlinear functions:

- **Process Model:**
  \[
  \mathbf{x}_{k} = f(\mathbf{x}_{k-1}, \mathbf{u}_{k}) + \mathbf{w}_{k}
  \]

- **Measurement Model:**
  \[
  \mathbf{z}_{k} = h(\mathbf{x}_{k}) + \mathbf{v}_{k}
  \]

The EKF uses Jacobian matrices to linearize \(f\) and \(h\):

- **State Transition Jacobian:**
  \[
  \mathbf{F}_{k} = \left. \frac{\partial f}{\partial \mathbf{x}} \right|_{\hat{\mathbf{x}}_{k-1}}
  \]

- **Measurement Jacobian:**
  \[
  \mathbf{H}_{k} = \left. \frac{\partial h}{\partial \mathbf{x}} \right|_{\hat{\mathbf{x}}_{k}}
  \]

##### 1.4.1.2.1.3. Applications

- **Navigation Systems:** Aerospace and marine navigation where the motion dynamics are nonlinear.
- **Robotics:** Mobile robot localization and mapping (SLAM).
- **Tracking Systems:** Radar and sonar tracking of maneuvering targets.

#### 1.4.1.2.2. Unscented Kalman Filter (UKF)

##### 1.4.1.2.2.1. Overview

The UKF addresses the inaccuracies arising from linearization in the EKF by using deterministic sampling (sigma points) to capture the mean and covariance estimates more accurately.

##### 1.4.1.2.2.2. Sigma Points

The UKF generates a set of sigma points that are propagated through the nonlinear functions:

- Captures up to the second-order statistics of the Gaussian distribution.
- Provides better approximations for nonlinear transformations.

##### 1.4.1.2.2.3. Applications

- **Nonlinear Control Systems:** Where higher accuracy is needed over the EKF.
- **sensor fusion:** Combining data from multiple sensors with nonlinear measurements.
- **Autonomous Vehicles:** State estimation in complex dynamic environments.

#### 1.4.1.2.3. Error-State Kalman Filter (ESKF)

##### 1.4.1.2.3.1. Overview

The ESKF estimates the error between the estimated state and the true state, rather than estimating the state directly. This is particularly useful for systems where the state variables exhibit slow changes or when initial estimates are available.

##### 1.4.1.2.3.2. Advantages

- **Numerical Stability:** By focusing on small errors, numerical issues due to large state values are minimized.
- **Simplified Linearization:** The error dynamics are often more linear than the state dynamics, simplifying the computation.

##### 1.4.1.2.3.3. Applications

- **Inertial Navigation Systems (INS):** Where small errors in position, velocity, and orientation need to be accurately estimated.
- **Robotics:** Precise localization and mapping, especially in SLAM applications.
- **Aerospace:** Attitude estimation for aircraft and satellites.

#### 1.4.1.2.4. Square Root Kalman Filter (SRKF)

##### 1.4.1.2.4.1. Overview

The SRKF maintains the square root of the covariance matrix to improve numerical stability.

##### 1.4.1.2.4.2. Advantages

- **Numerical Stability:** Avoids direct computation of the covariance matrix, reducing round-off errors.
- **Positive Definiteness:** Ensures the covariance matrix remains positive definite.

##### 1.4.1.2.4.3. Applications

- **High-Precision Systems:** Where numerical errors can accumulate over time.
- **Large-Scale Systems:** With significant computational demands.

#### 1.4.1.2.5. Information Filter (Inverse Covariance Filter)

##### 1.4.1.2.5.1. Overview

The Information Filter operates on the information matrix (inverse of the covariance matrix) and information vector.

##### 1.4.1.2.5.2. Advantages

- **Sparsity Exploitation:** Efficient for systems where the information matrix is sparse.
- **Distributed Estimation:** Facilitates decentralized estimation in networked systems.

##### 1.4.1.2.5.3. Applications

- **Sensor Networks:** Distributed state estimation.
- **Multi-Robot Systems:** Where robots share information to estimate a common state.

#### 1.4.1.2.6. Ensemble Kalman Filter (EnKF)

##### 1.4.1.2.6.1. Overview

The EnKF uses a Monte Carlo approach with an ensemble of random samples to estimate the state distribution.

##### 1.4.1.2.6.2. Applications

- **Meteorology:** Weather prediction and climate modeling.
- **Oceanography:** Estimating ocean states from sparse measurements.

#### 1.4.1.2.7. Particle Filter (Sequential Monte Carlo Methods)

Although not a Kalman filter, particle filters are similar recursive Bayesian estimators suitable for highly nonlinear and non-Gaussian systems.



### 1.4.1.3. Applications of Different Kalman Filter Variants

#### 1.4.1.3.1. Linear Kalman Filter

- **Finance:** Estimating market trends and filtering economic indicators.
- **Signal Processing:** Noise reduction in signals, system identification.
- **Control Systems:** Classical control applications with linear dynamics.

#### 1.4.1.3.2. Extended Kalman Filter (EKF)

- **GPS Navigation:** Position and velocity estimation.
- **Robotics:** Odometry and sensor fusion for mobile robots.
- **Biomedical Engineering:** Heart rate estimation from noisy measurements.

#### 1.4.1.3.3. Unscented Kalman Filter (UKF)

- **Aerospace Engineering:** Attitude and orbit determination for spacecraft.
- **Automotive Applications:** Vehicle tracking and advanced driver-assistance systems (ADAS).
- **Nonlinear System Identification:** Estimating parameters in complex models.

#### 1.4.1.3.4. Error-State Kalman Filter (ESKF)

- **Inertial Measurement Unit (IMU) Integration:** Correcting drift errors in accelerometers and gyroscopes.
- **Mobile Robotics:** High-precision localization in GPS-denied environments.
- **Virtual Reality (VR):** Head and motion tracking for immersive experiences.

#### 1.4.1.3.5. Square Root Kalman Filter (SRKF)

- **High-Precision Navigation:** Submarine and missile guidance systems.
- **Space Missions:** Deep space navigation where precision is critical.

#### 1.4.1.3.6. Information Filter

- **Decentralized Estimation:** Collaborative tracking in sensor networks.
- **Multisensor Data Fusion:** Integrating measurements from distributed sensors.

#### 1.4.1.3.7. Ensemble Kalman Filter (EnKF)

- **Geosciences:** Assimilating data from various sources for environmental modeling.
- **Hydrology:** Estimating water flow and levels in river basins.


### 1.4.1.4. Choosing the Appropriate Kalman Filter Variant

#### 1.4.1.4.1. System Linearity

- **Linear Systems:** Use the standard Kalman Filter.
- **Mildly Nonlinear Systems:** EKF may suffice, but be cautious of linearization errors.
- **Highly Nonlinear Systems:** UKF or particle filters are more appropriate.

#### 1.4.1.4.2. Computational Resources

- **Limited Resources:** EKF is less computationally intensive than UKF.
- **High Accuracy Needed:** UKF provides better estimates at the expense of computation.

#### 1.4.1.4.3. Noise Characteristics

- **Gaussian Noise:** Standard KF, EKF, UKF assume Gaussian noise.
- **Non-Gaussian Noise:** Particle filters or other nonlinear estimators are preferable.

#### 1.4.1.4.4. Application Requirements

- **Precision vs. Speed:** SRKF is preferred for precision, while standard KF is faster.
- **Distributed Systems:** Information Filters are suitable for decentralized estimation.



### 1.4.1.5. Kalman Filter Algorithm Steps

#### 1.4.1.5.1. Standard Kalman Filter Steps

1. **Initialization:**
   - Set initial state estimate \(\hat{\mathbf{x}}_{0}\) and covariance \(\mathbf{P}_{0}\).

2. **Prediction Step:**
   - Predict the next state:
     \[
     \hat{\mathbf{x}}_{k|k-1} = \mathbf{A}_{k}\hat{\mathbf{x}}_{k-1|k-1} + \mathbf{B}_{k}\mathbf{u}_{k}
     \]
   - Predict the covariance:
     \[
     \mathbf{P}_{k|k-1} = \mathbf{A}_{k}\mathbf{P}_{k-1|k-1}\mathbf{A}_{k}^{T} + \mathbf{Q}_{k}
     \]

3. **Update Step:**
   - Compute the Kalman Gain:
     \[
     \mathbf{K}_{k} = \mathbf{P}_{k|k-1}\mathbf{H}_{k}^{T}(\mathbf{H}_{k}\mathbf{P}_{k|k-1}\mathbf{H}_{k}^{T} + \mathbf{R}_{k})^{-1}
     \]
   - Update the estimate with measurement \(\mathbf{z}_{k}\):
     \[
     \hat{\mathbf{x}}_{k|k} = \hat{\mathbf{x}}_{k|k-1} + \mathbf{K}_{k}(\mathbf{z}_{k} - \mathbf{H}_{k}\hat{\mathbf{x}}_{k|k-1})
     \]
   - Update the covariance:
     \[
     \mathbf{P}_{k|k} = (\mathbf{I} - \mathbf{K}_{k}\mathbf{H}_{k})\mathbf{P}_{k|k-1}
     \]

#### 1.4.1.5.2. EKF and UKF Adaptations

- **EKF:** Incorporate Jacobians in prediction and update steps.
- **UKF:** Use sigma points to approximate the distributions.



### 1.4.1.6. Practical Considerations

#### 1.4.1.6.1. Tuning the Filter

- **Process Noise Covariance (\(\mathbf{Q}\)):** Adjust to reflect how much uncertainty is in the model.
- **Measurement Noise Covariance (\(\mathbf{R}\)):** Set based on the accuracy of the sensors.

#### 1.4.1.6.2. Initialization

- **State Estimate:** Should be as close as possible to the true initial state.
- **Covariance Matrix:** Reflect the confidence in the initial estimate.

#### 1.4.1.6.3. Numerical Stability

- **Covariance Matrix Symmetry:** Ensure that \(\mathbf{P}\) remains symmetric and positive semi-definite.
- **Avoiding Divergence:** Monitor innovations (measurement residuals) to detect divergence.



As the conclusion, the Kalman Filter and its variants are powerful tools for state estimation in various systems, especially when dealing with uncertainties and noise. By selecting the appropriate variant based on the system's characteristics and application requirements, one can achieve robust and accurate estimation results.

Understanding the mathematical foundations, assumptions, and limitations of each filter variant is crucial for successful implementation. Continuous advancements in filter design and computation methods are expanding their applicability to increasingly complex and nonlinear systems.





### 1.4.2 Computer Vision - è®¡ç®—æœºè§†è§‰ <a id="Scene-Understanding"></a>

#### 1.4.2.1 2D Vision - äºŒç»´è§†è§‰ <a id="2D-Vision"></a>
(Coming Soon...)  

#### 1.4.2.2 3D Vision - ä¸‰ç»´è§†è§‰ <a id="3D-Vision"></a>
(Coming Soon...)  

#### 1.4.2.3 4D Vision - å››ç»´è§†è§‰ <a id="4D-Vision"></a>
(Coming Soon...)  

#### 1.4.2.4 Subdivision of Application Domains - åº”ç”¨é¢†åŸŸç»†åˆ† <a id="Subdivision-of-application-domains"></a>

##### 1.4.2.4.1 Visual Prompting - è§†è§‰æç¤º <a id="Visual-Prompting"></a>
(Coming Soon...)  

##### 1.4.2.4.2 Affordance Grounding - å¯ä¾›æ€§é”šå®š <a id="Affordance-Grounding"></a>

###### 1.4.2.4.2.1 2D - äºŒç»´ <a id="Two-Dimension"></a>
(Coming Soon...)  

###### 1.4.2.4.2.2 3D - ä¸‰ç»´ <a id="Three-Dimension"></a>
(Coming Soon...)  



### 1.4.2 Scene Understanding - åœºæ™¯ç†è§£ <a id="Scene-Understanding"></a>

#### 1.4.2.1 Segmentation - å›¾åƒåˆ†å‰² <a id="Segmentation"></a>
(Coming Soon...)  



## 1.5 Learning - å­¦ä¹  <a id="Learning"></a>

### 1.5.1 Intro to Machine Learning - æœºå™¨å­¦ä¹ å…¥é—¨ <a id="Intro-to-Machine-Learning"></a>
(Coming Soon...)  

### 1.5.2 Reinforcement Learning - å¼ºåŒ–å­¦ä¹  <a id="Reinforcement-Learning"></a>
(Coming Soon...)  

### 1.5.3 Imitation Learning - æ¨¡ä»¿å­¦ä¹  <a id="Imitation-Learning"></a>
(Coming Soon...)  



## 1.6 Multi-Robot Systems - å¤šæœºå™¨äººç³»ç»Ÿ <a id="Multi-Robot-Systems"></a>
(Coming Soon...)  



## 1.7 Simulation and Modeling - ä»¿çœŸä¸å»ºæ¨¡ <a id="Simulation-and-Modeling"></a>
(Coming Soon...)  



## 1.8 Physical Interaction - ç‰©ç†äº¤äº’ <a id="Physical-Interaction"></a>
(Coming Soon...)  



## 1.9 Ethics and Social Implications - ä¼¦ç†ä¸ç¤¾ä¼šé—®é¢˜ <a id="Ethics-and-Social-Implications"></a>
(Coming Soon...)  



# 2. Tools - å·¥å…· <a id="tools"></a>

## 2.1 Software - è½¯ä»¶ <a id="software"></a>

### 2.1.1 General Tools - å¸¸ç”¨å·¥å…· <a id="General-Tools"></a>
(Coming Soon...)  

### 2.1.2 Simulators - ä»¿çœŸå™¨ <a id="simulators"></a>
(Coming Soon...)  

### 2.1.3 Robot Description - æœºå™¨äººæè¿°æ ¼å¼ <a id="Robot-Description"></a>
(Coming Soon...)  



## 2.2 Hardware - ç¡¬ä»¶ <a id="hardware"></a>
(Coming Soon...)  



# 3. Literature Review - æ–‡çŒ®ç»¼è¿° <a id="literature-review"></a>

## 3.1 Traditional Control - ä¼ ç»Ÿæ§åˆ¶ <a id="Traditional-Control"></a>

- A manipulator-assisted multiple UAV landing system for USV subject to disturbance 
*R. Xu, C. Liu, Z. Cao, Y. Wang and H. Qian; Ocean Engineering 2024 Vol. 299 Pages 117306; DOI: 10.1016/j.oceaneng.2024.117306*

## 3.2 Model Predictive Control - æ¨¡å‹é¢„æµ‹æ§åˆ¶ <a id="Model-Predictive-Control"></a>


- Confidence-Aware Object Capture for a Manipulator Subject to Floating-Base Disturbances 
*R. Xu, Z. Jiang, B. Liu, Y. Wang and H. Qian; IEEE Transactions on Robotics 2024 Vol. 40 Pages 4396-4413; DOI: 10.1109/tro.2024.3463476*

  **æƒ³è§£å†³çš„é—®é¢˜**

  æœ¬è®ºæ–‡æ—¨åœ¨è§£å†³åœ¨æ³¢æµªæ‰°åŠ¨ä¸‹ï¼Œæ— äººè‰‡ï¼ˆUSVï¼‰ä¸Šçš„æœºæ¢°è‡‚æ•è·ç©ºä¸­é™æ­¢ç›®æ ‡ï¼ˆå¦‚æ— äººæœºï¼‰çš„é—®é¢˜ã€‚ç”±äºæ³¢æµªå¼•èµ·çš„åŸºåº§è¿åŠ¨æ˜¯å‡†å‘¨æœŸä¸”å¿«é€Ÿçš„ï¼Œå¯¼è‡´ç›®æ ‡è¿åŠ¨é¢„æµ‹ç²¾åº¦ä½ï¼Œä»¥åŠæœºæ¢°è‡‚å—é™çš„ä¸»åŠ¨åŠ›çŸ©ä½¿å¾—å®æ—¶è¿½è¸ªå’Œæ•è·ç›®æ ‡å˜å¾—å›°éš¾ã€‚ä¼ ç»Ÿçš„æ–¹æ³•ä¾èµ–äºå‡†ç¡®çš„è¿åŠ¨é¢„æµ‹å’Œè¶³å¤Ÿçš„æ‰§è¡Œå™¨åŠ›çŸ©ï¼Œç„¶è€Œè¿™äº›æ¡ä»¶åœ¨å®é™…ä¸­å¾ˆéš¾æ»¡è¶³ã€‚

  **å…·ä½“åšæ³•**

  *ç®—æ³•éƒ¨åˆ†ï¼š*

  1. **è¿åŠ¨é¢„æµ‹ä¸ç½®ä¿¡åº¦è¯„ä¼°ï¼š**
    - **æ³¢ãƒ¬ãƒƒãƒˆç½‘ç»œï¼ˆWavelet Network, WNï¼‰é¢„æµ‹ï¼š** ä½¿ç”¨å®æ—¶è®­ç»ƒçš„WNæ¥é¢„æµ‹ç›®æ ‡åœ¨åŸºåº§åæ ‡ç³»ä¸‹çš„è¿åŠ¨è½¨è¿¹ã€‚WNèƒ½æœ‰æ•ˆæ•æ‰æ³¢æµªæ‰°åŠ¨ä¸‹çš„éçº¿æ€§å’Œä¸ç¡®å®šæ€§ã€‚
    - **ç½®ä¿¡åº¦åˆ†æï¼š** ä¸ºäº†è¯„ä¼°é¢„æµ‹è´¨é‡ï¼Œé‡‡ç”¨è´å¶æ–¯æ–¹æ³•è®¡ç®—é¢„æµ‹çš„ç½®ä¿¡åº¦ã€‚å¾—åˆ°ä¸€ä¸ªå®æ—¶çš„ç½®ä¿¡åº¦åŒºé—´ï¼ˆconfidence tubeï¼‰ï¼Œç”¨äºå¤šæ­¥é¢„æµ‹çš„å‡†ç¡®æ€§è¯„ä¼°ã€‚

  2. **ç½®ä¿¡åº¦æ„ŸçŸ¥çš„è¿åŠ¨è§„åˆ’ï¼š**
    - **æ•è·ä½ç½®é€‰æ‹©ï¼š** åœ¨é¢„æµ‹çš„è½¨è¿¹ä¸Šé€‰æ‹©ä¸€ä¸ªç½®ä¿¡åº¦æœ€é«˜çš„æ•è·ä½ç½®ï¼Œé€šè¿‡æœ€å¤§åŒ–æ•è·ä½ç½®çš„ç½®ä¿¡åº¦ï¼Œç¡®å®šæœ€ä½³çš„æ•è·æ—¶åˆ»ã€‚
    - **è¿åŠ¨è½¨è¿¹è§„åˆ’ï¼š** å½¢æˆä¸€ä¸ªéçº¿æ€§ä¼˜åŒ–é—®é¢˜ï¼Œç”Ÿæˆæœºæ¢°è‡‚åœ¨ä»»åŠ¡ç©ºé—´ä¸­çš„æ•è·è½¨è¿¹ã€‚è¯¥ä¼˜åŒ–åŒæ—¶è€ƒè™‘äº†æ•è·çš„ç½®ä¿¡åº¦å’Œæœºæ¢°è‡‚çš„è¿åŠ¨å¯è¡Œæ€§ã€‚
    - **è®¡ç®—æ•ˆç‡æå‡ï¼š** ä¸ºäº†ä¿è¯å®æ—¶æ€§ï¼ˆåœ¨0.2ç§’å†…å®Œæˆæ‰€æœ‰è®¡ç®—ï¼‰ï¼Œå°†ä¼˜åŒ–é—®é¢˜æ‹†åˆ†ä¸ºä¸¤ä¸ªæ›´ç®€å•çš„é—®é¢˜ï¼šé¦–å…ˆæ±‚è§£æ•è·ä½ç½®ï¼Œç„¶åè§„åˆ’è¿åŠ¨è½¨è¿¹ã€‚

  *ç³»ç»Ÿï¼ˆè®¾è®¡ï¼‰éƒ¨åˆ†ï¼š*

  - **æœºæ¢°è‡‚ç³»ç»Ÿè®¾è®¡ï¼š** ä½¿ç”¨ä¸€ä¸ªå†—ä½™åº¦è¾ƒé«˜çš„æœºæ¢°è‡‚ï¼Œå®‰è£…åœ¨ä¼ºæœå¹³å°ä¸Šï¼Œä»¥æ¨¡æ‹Ÿæµ®åŠ¨åŸºåº§çš„æ‰°åŠ¨ã€‚æœºæ¢°è‡‚æœ«ç«¯é…å¤‡ç”µç£é“ï¼Œèƒ½å¤Ÿåœ¨æ¥è§¦åˆ°ç›®æ ‡åç«‹å³æ•è·ã€‚
  - **å®éªŒå¹³å°æ­å»ºï¼š** åœ¨å®éªŒä¸­ï¼Œåˆ©ç”¨çœŸå®çš„æ— äººè‰‡è¿åŠ¨æ•°æ®ï¼Œé€šè¿‡ä¼ºæœå¹³å°å†ç°åŸºåº§çš„å…­è‡ªç”±åº¦è¿åŠ¨ï¼ŒåŒ…æ‹¬æ»šè½¬ã€ä¿¯ä»°ã€åèˆªã€æ¨è¿›ã€æ¨ªç§»å’Œå‡æ²‰ã€‚
  - **ä¼ æ„Ÿä¸æ§åˆ¶ç³»ç»Ÿï¼š** ä½¿ç”¨è¿åŠ¨æ•æ‰ç³»ç»Ÿå®æ—¶è·å–ç›®æ ‡å’ŒåŸºåº§çš„ä½ç½®å’Œå§¿æ€ä¿¡æ¯ã€‚æ§åˆ¶ç³»ç»ŸåŸºäºROSæ¶æ„ï¼Œä»¥é«˜é¢‘ç‡ï¼ˆ1kHzï¼‰åœ¨å…³èŠ‚ä½ç½®å±‚é¢æ§åˆ¶æœºæ¢°è‡‚ã€‚

  **æ•ˆæœ**

  - **å®éªŒéªŒè¯ï¼š** é€šè¿‡æ¨¡æ‹Ÿå’Œå®é™…å®éªŒï¼ŒéªŒè¯äº†æ‰€ææ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚åœ¨è¿›è¡Œäº†è¶…è¿‡150æ¬¡å®éªŒåï¼Œç»“æœæ˜¾ç¤ºï¼š
    - **æˆåŠŸç‡ï¼š** åœ¨åŸºåº§æ‰§è¡ŒçœŸå®æ— äººè‰‡è¿åŠ¨çš„æƒ…å†µä¸‹ï¼Œæ‰€ææ–¹æ³•å®ç°äº†80%çš„æ•è·æˆåŠŸç‡ã€‚
    - **ç²¾åº¦æå‡ï¼š** ç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼Œæ•è·ç²¾åº¦æ˜¾è‘—æé«˜ï¼Œå‡æ–¹è¯¯å·®ï¼ˆMAEï¼‰é™ä½äº†25%ä»¥ä¸Šã€‚
    - **é²æ£’æ€§ï¼š** å³ä½¿åœ¨é¢„æµ‹ç²¾åº¦æ— æ³•æŒç»­ä¿æŒçš„æƒ…å†µä¸‹ï¼Œé€šè¿‡ç½®ä¿¡åº¦è¯„ä¼°å’Œåˆå§‹åŒ–æ–¹æ³•ï¼Œæé«˜äº†æ•è·çš„å¯é æ€§ã€‚

  **å…³é”®è¯**
  - ç½®ä¿¡åº¦åˆ†æï¼Œæµ®åŠ¨åŸºåº§æœºæ¢°è‡‚ï¼Œè¿åŠ¨è§„åˆ’ï¼Œç›®æ ‡æ•è·ï¼Œæ³¢ãƒ¬ãƒƒãƒˆç½‘ç»œï¼Œè´å¶æ–¯æ–¹æ³•ï¼Œå®æ—¶æ§åˆ¶ï¼Œæ— äººè‰‡ï¼Œè‡ªåŠ¨åŒ–ç³»ç»Ÿ

<!-- ##
- Confidence-Aware Object Capture for a Manipulator Subject to Floating-Base Disturbances 
*R. Xu, Z. Jiang, B. Liu, Y. Wang and H. Qian; IEEE Transactions on Robotics 2024 Vol. 40 Pages 4396-4413; DOI: 10.1109/tro.2024.3463476* -->


## 3.3 Vision Language Model - è§†è§‰-è¯­è¨€æ¨¡å‹ <a id="Vision-Language-Model"></a>
(Coming Soon...)  

## 3.4 Vision Language Action Model - è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ <a id="Vision-Language-Action"></a>
(Coming Soon...)  

## 3.5 Dual System - åŒç³»ç»Ÿ <a id="Dual-System"></a>
(Coming Soon...)  


# 4. Paper List Links - è®ºæ–‡åˆ—è¡¨é“¾æ¥ <a id="paper-list-link"></a>
- [Awesome-LLM-Robotics: A repo contains a curative list of papers using Large Language/Multi-Modal Models for Robotics/RL](https://github.com/GT-RIPL/Awesome-LLM-Robotics)
- [SOTA Paper Rating - Weiyang Jin](https://waynejin0918.github.io/SOTA-paper-rating.io/)
- [Paper List For EmbodiedAI - Tianxing Chen](https://github.com/TianxingChen/Paper-List-For-EmbodiedAI)
- [Paper List - Yanjie Ze](https://github.com/YanjieZe/Paper-List)



# 5. Acknowledgement - è‡´è°¢ <a id="acknowledgement"></a>
>æ–‡ä¸­éƒ¨åˆ†å†…å®¹å¯èƒ½åŒ…æ‹¬æˆ‘ä»¬æœ‰accessæƒé™ä½†æ˜¯ä¸å¯¹å…¬ä¼—å¼€æ”¾çš„å†…å®¹ï¼ˆæ¯”å¦‚éƒ¨åˆ†è®ºæ–‡çš„PDFï¼‰ï¼Œä»…åšå­¦æœ¯åˆ†äº«ï¼Œå¦‚æœ‰ä¾µæƒï¼Œè¯·æ‚¨ç¬¬ä¸€æ—¶é—´è”ç³»æˆ‘ä»¬åˆ é™¤ã€‚è¯·å‹¿å°†æœ¬ä»“åº“ä¸­çš„ä»»ä½•å†…å®¹ç”¨ä½œå•†ä¸šç›®çš„ã€‚å¦‚æœ‰ç›¸åº”éƒ¨åˆ†å› æˆ‘ä»¬ç–å¿½ï¼ˆæ¯”å¦‚å¼•ç”¨äº†ç›¸å…³çš„å†…å®¹ä½†æ˜¯å¿˜è®°æ ‡æ˜å‡ºå¤„ï¼‰ï¼Œè¯·éº»çƒ¦è”ç³»æˆ‘ä»¬ï¼Œæˆ‘ä»¬ä¼šç¬¬ä¸€æ—¶é—´è¿›è¡Œupdateã€‚

æœ¬æ–‡è½¬è½½/å¼•ç”¨äº†ä¸€ä¸‹ä¸€äº›å›¢ä½“/ä¸ªäººçš„å†…å®¹ï¼Œæˆ‘ä»¬å¯¹ä»–ä»¬çš„è´¡çŒ®è¡¨ç¤ºæ„Ÿè°¢ï¼Œä»¥ä¸‹æ˜¯å¼•ç”¨åˆ—è¡¨ï¼š

[1] Course Materials from CUHK, Shenzhen [Introduction to Robotics](https://github.com/yimouwu/Robotics-and-Embodied-AI-Review/tree/main/Awesome%20Course%20Materials/Introduction%20to%20Robotics)ï¼Œ[2] Feishu Docs [æœ¨æœ¨å…·èº«çŸ¥è¯†åº“](https://yv6uc1awtjc.feishu.cn/wiki/WPTzw9ON0ivIVrkLjVocNZh8nLf?from=from_copylink)ï¼Œ[3] Github repo [Embodied-AI-Guide](https://github.com/TianxingChen/Embodied-AI-Guide)ï¼Œ[4] Github repo [Awesome-Embodied-AI](https://github.com/yunlongdong/Awesome-Embodied-AI)

####
# About us - å…³äºæˆ‘ä»¬
###### "å·±æ¬²ç«‹è€Œç«‹äººï¼Œå·±æ¬²è¾¾è€Œè¾¾äºº"
æˆ‘ä»¬æ˜¯ä¸€ä¸ªç”±æœºå™¨äººä¸å…·èº«åˆå­¦è€…ç»„æˆçš„å›¢é˜Ÿ, å¸Œæœ›èƒ½å¤Ÿé€šè¿‡æˆ‘ä»¬è‡ªå·±çš„å­¦ä¹ ã€ç§‘ç ”ç»éªŒ, ä¸ºå¿—åŒé“åˆçš„æœ‹å‹æä¾›ä¸€äº›å¸®åŠ©ã€‚æ¬¢è¿æ›´å¤šæœ‹å‹åŠ å…¥æˆ‘ä»¬çš„é¡¹ç›®, ä¹Ÿå¾ˆæ¬¢è¿äº¤å‹ã€å­¦æœ¯åˆä½œ, æœ‰ä»»ä½•é—®é¢˜, å¯ä»¥è”ç³»é‚®ç®±`yimouwu0@gmail.com`ã€‚

<p><b>ğŸ Contributors</b>: <a href="https://yimouwu.github.io/">å´è´»è°‹ (25'æ¸¯ä¸­æ–‡MPhil)</a> 
</p> 

<a href="https://github.com/yimouwu/Robotics-and-Embodied-AI-Review/contributors">
  <img src="https://contrib.rocks/image?repo=yimouwu/Robotics-and-Embodied-AI-Review" />
</a>

#####
> å…³äºæœ¬ä»“åº“çš„çŸ¥è¯†è®¨è®ºï¼Œæˆ–è€…ä»»ä½•å…¶ä»–é—®é¢˜,æ¬¢è¿è”ç³»å´è´»è°‹ï¼ˆ25'fall CUHK åŒ»å­¦é™¢å¤–ç§‘ç³» MPhilï¼Œæ–¹å‘ä¸ºæœºå™¨äººï¼ˆåŒ»ç–—ï¼‰ä¸å…·èº«æ™ºèƒ½ï¼‰å¾®ä¿¡ï¼šyimouwu777 æˆ–è€… é‚®ç®±ï¼šyimouwu0@gmail.com

# ğŸ‘ Citation <a id="citation"></a>

å¦‚æœæœ¬ä»“åº“å¯¹ä½ çš„ç ”ç©¶æˆ–å­¦ä¹ æœ‰æ‰€å¸®åŠ©ï¼Œè¯·å¼•ç”¨ï¼š
```bibtex
@misc{roboticsandembodiedaireview2025,
  title     = {Robotics-and-Embodied-AI-Review},
  author    = {Robotics-and-Embodied-AI-Review-Contributors},
  month     = {June},
  year      = {2025},
  url       = {https://github.com/yimouwu/Robotics-and-Embodied-AI-Review},
}
```


# ğŸ·ï¸ License <a id="license"></a>

This repository is released under the MIT license. See [LICENSE](./LICENSE) for additional details.



# â­ï¸ Star History <a id="star-history"></a>

## Star History
[![Star History Chart](https://api.star-history.com/svg?repos=yimouwu/Robotics-and-Embodied-AI-Review&type=Date)](https://www.star-history.com/#yimouwu/Robotics-and-Embodied-AI-Review&Date)
